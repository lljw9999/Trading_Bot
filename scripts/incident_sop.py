#!/usr/bin/env python3
"""
Incident Standard Operating Procedure (SOP)

Implements the 5-step incident response procedure:
1. Stabilize - Set global halt, freeze capital, snapshot state
2. Triage - Classify P0/P1/P2 severity
3. Recover - Canary rollback, verify recon, run preflight
4. Report - File post-mortem stub within 60 minutes
5. Prevent - Add test/alert, link changes to incident record
"""

import argparse
import json
import logging
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional
import sys
import subprocess

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

try:
    import redis

    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False

logger = logging.getLogger("incident_sop")


class IncidentSOPManager:
    """
    Manages incident response according to standard operating procedure.
    Provides automated and guided manual steps for incident resolution.
    """

    def __init__(self):
        """Initialize incident SOP manager."""
        self.redis_client = None
        if REDIS_AVAILABLE:
            try:
                self.redis_client = redis.Redis(decode_responses=True)
            except Exception as e:
                logger.warning(f"Redis unavailable: {e}")

        # Incident severity definitions
        self.severity_definitions = {
            "P0": {
                "description": "Funds at risk - immediate financial loss or exposure",
                "examples": [
                    "Reconciliation breach with position mismatch",
                    "Runaway orders causing large losses",
                    "Security breach or unauthorized access",
                ],
                "sla_minutes": 15,
            },
            "P1": {
                "description": "Live degradation - trading impaired but funds protected",
                "examples": [
                    "RL entropy collapse preventing execution",
                    "Market data feed failure",
                    "Exchange connectivity issues",
                ],
                "sla_minutes": 30,
            },
            "P2": {
                "description": "Shadow/monitoring only - no live trading impact",
                "examples": [
                    "Dashboard display issues",
                    "Non-critical feature degradation",
                    "Backup process failures",
                ],
                "sla_minutes": 120,
            },
        }

        self.incident_id_counter = None
        logger.info("Initialized incident SOP manager")

    def step1_stabilize(self, incident_description: str = "") -> Dict[str, any]:
        """
        Step 1: Stabilize the system.
        - Set global halt
        - Freeze capital cap at current level
        - Snapshot Redis & logs

        Args:
            incident_description: Description of the incident

        Returns:
            Results of stabilization actions
        """
        try:
            logger.critical("ðŸ›‘ STEP 1: STABILIZE - Executing emergency stabilization")

            stabilization_results = {
                "timestamp": datetime.now().isoformat(),
                "step": "1_stabilize",
                "incident_description": incident_description,
                "actions": {},
            }

            # Set global halt
            if self.redis_client:
                self.redis_client.set("mode", "halt")
                stabilization_results["actions"]["global_halt"] = {
                    "executed": True,
                    "timestamp": datetime.now().isoformat(),
                }
            else:
                logger.warning("Redis unavailable - cannot set global halt")
                stabilization_results["actions"]["global_halt"] = {
                    "executed": False,
                    "reason": "Redis unavailable",
                }

            # Freeze capital cap
            if self.redis_client:
                current_cap = self.redis_client.get("risk:capital_effective") or "10000"
                self.redis_client.set("risk:capital_frozen", current_cap)
                self.redis_client.set("risk:capital_ramp_enabled", "0")
                stabilization_results["actions"]["freeze_capital"] = {
                    "executed": True,
                    "frozen_at": current_cap,
                    "timestamp": datetime.now().isoformat(),
                }
            else:
                stabilization_results["actions"]["freeze_capital"] = {
                    "executed": False,
                    "reason": "Redis unavailable",
                }

            # Snapshot Redis state
            snapshot_path = self._snapshot_redis()
            stabilization_results["actions"]["redis_snapshot"] = {
                "executed": snapshot_path is not None,
                "path": snapshot_path,
                "timestamp": datetime.now().isoformat(),
            }

            # Snapshot logs
            log_snapshot_path = self._snapshot_logs()
            stabilization_results["actions"]["log_snapshot"] = {
                "executed": log_snapshot_path is not None,
                "path": log_snapshot_path,
                "timestamp": datetime.now().isoformat(),
            }

            logger.info("âœ… STEP 1 COMPLETE: System stabilized")
            return stabilization_results

        except Exception as e:
            logger.error(f"Error in stabilization step: {e}")
            return {"step": "1_stabilize", "error": str(e)}

    def step2_triage(self, incident_description: str) -> Dict[str, any]:
        """
        Step 2: Triage and classify incident severity.

        Args:
            incident_description: Description of the incident

        Returns:
            Triage results with severity classification
        """
        try:
            logger.info("ðŸ” STEP 2: TRIAGE - Classifying incident severity")

            triage_results = {
                "timestamp": datetime.now().isoformat(),
                "step": "2_triage",
                "incident_description": incident_description,
                "severity": None,
                "classification_reason": "",
                "sla_minutes": None,
            }

            # Automated severity detection based on keywords
            description_lower = incident_description.lower()

            # P0 indicators
            p0_keywords = [
                "recon",
                "reconciliation",
                "breach",
                "mismatch",
                "runaway",
                "large loss",
                "security",
                "unauthorized",
                "funds at risk",
            ]
            if any(keyword in description_lower for keyword in p0_keywords):
                triage_results["severity"] = "P0"
                triage_results["classification_reason"] = (
                    "Automated: Funds at risk indicators detected"
                )
                triage_results["sla_minutes"] = self.severity_definitions["P0"][
                    "sla_minutes"
                ]

            # P1 indicators
            elif any(
                keyword in description_lower
                for keyword in [
                    "entropy",
                    "collapse",
                    "market data",
                    "feed failure",
                    "connectivity",
                    "execution",
                    "impaired",
                ]
            ):
                triage_results["severity"] = "P1"
                triage_results["classification_reason"] = (
                    "Automated: Live degradation indicators detected"
                )
                triage_results["sla_minutes"] = self.severity_definitions["P1"][
                    "sla_minutes"
                ]

            # Default to P2
            else:
                triage_results["severity"] = "P2"
                triage_results["classification_reason"] = (
                    "Default: No P0/P1 indicators detected"
                )
                triage_results["sla_minutes"] = self.severity_definitions["P2"][
                    "sla_minutes"
                ]

            # Add severity details
            triage_results["severity_details"] = self.severity_definitions[
                triage_results["severity"]
            ]

            # Calculate SLA deadline
            sla_deadline = datetime.now() + timedelta(
                minutes=triage_results["sla_minutes"]
            )
            triage_results["sla_deadline"] = sla_deadline.isoformat()

            logger.info(
                f"âœ… STEP 2 COMPLETE: Classified as {triage_results['severity']} "
                f"(SLA: {triage_results['sla_minutes']} min)"
            )

            return triage_results

        except Exception as e:
            logger.error(f"Error in triage step: {e}")
            return {"step": "2_triage", "error": str(e)}

    def step3_recover(self) -> Dict[str, any]:
        """
        Step 3: Recover system to safe state.
        - Canary rollback
        - Verify recon=clean
        - Run preflight supercheck

        Returns:
            Recovery results
        """
        try:
            logger.info("ðŸ”§ STEP 3: RECOVER - Restoring system to safe state")

            recovery_results = {
                "timestamp": datetime.now().isoformat(),
                "step": "3_recover",
                "actions": {},
            }

            # Canary rollback
            rollback_result = self._execute_canary_rollback()
            recovery_results["actions"]["canary_rollback"] = rollback_result

            # Verify reconciliation clean
            recon_result = self._verify_reconciliation()
            recovery_results["actions"]["verify_recon"] = recon_result

            # Run preflight supercheck
            preflight_result = self._run_preflight_supercheck()
            recovery_results["actions"]["preflight_check"] = preflight_result

            # Determine if recovery successful
            recovery_success = all(
                [
                    rollback_result.get("success", False),
                    recon_result.get("clean", False),
                    preflight_result.get("all_green", False),
                ]
            )

            recovery_results["recovery_successful"] = recovery_success

            if recovery_success:
                logger.info("âœ… STEP 3 COMPLETE: System recovered to safe state")
            else:
                logger.warning("âš ï¸ STEP 3 PARTIAL: Recovery issues detected")

            return recovery_results

        except Exception as e:
            logger.error(f"Error in recovery step: {e}")
            return {"step": "3_recover", "error": str(e)}

    def step4_report(self, incident_data: Dict[str, any]) -> Dict[str, any]:
        """
        Step 4: File post-mortem stub within 60 minutes.

        Args:
            incident_data: Combined data from previous steps

        Returns:
            Report filing results
        """
        try:
            logger.info("ðŸ“ STEP 4: REPORT - Filing post-mortem stub")

            # Generate incident ID
            incident_id = self._generate_incident_id()

            # Create post-mortem stub
            postmortem_stub = {
                "incident_id": incident_id,
                "timestamp": datetime.now().isoformat(),
                "title": f"Incident {incident_id}: {incident_data.get('incident_description', 'Unknown')}",
                "severity": incident_data.get("triage", {}).get("severity", "Unknown"),
                "who": {
                    "reporter": "incident_sop_automation",
                    "responder": "on_call_engineer",
                    "stakeholders": ["trading_ops", "risk_management"],
                },
                "what": {
                    "description": incident_data.get("incident_description", ""),
                    "symptoms": incident_data.get("symptoms", []),
                    "impact": self._determine_impact(incident_data),
                },
                "when": {
                    "detected": incident_data.get("stabilization", {}).get("timestamp"),
                    "stabilized": incident_data.get("stabilization", {}).get(
                        "timestamp"
                    ),
                    "recovered": incident_data.get("recovery", {}).get("timestamp"),
                },
                "why": {
                    "root_cause": "TBD - Investigation required",
                    "contributing_factors": [],
                    "analysis_pending": True,
                },
                "next": {
                    "immediate_actions": [
                        "Complete root cause analysis",
                        "Implement prevention measures",
                        "Update monitoring/alerting",
                    ],
                    "follow_up_timeline": "48 hours for full analysis",
                    "prevention_items": [],
                },
                "timeline": self._build_incident_timeline(incident_data),
                "attachments": {
                    "redis_snapshot": incident_data.get("stabilization", {})
                    .get("actions", {})
                    .get("redis_snapshot", {})
                    .get("path"),
                    "log_snapshot": incident_data.get("stabilization", {})
                    .get("actions", {})
                    .get("log_snapshot", {})
                    .get("path"),
                },
            }

            # Save post-mortem stub
            reports_dir = Path("artifacts/incidents")
            reports_dir.mkdir(parents=True, exist_ok=True)

            postmortem_file = (
                reports_dir / f"incident_{incident_id}_postmortem_stub.json"
            )
            with open(postmortem_file, "w") as f:
                json.dump(postmortem_stub, f, indent=2)

            # Store in Redis for tracking
            if self.redis_client:
                self.redis_client.set(
                    f"incident:{incident_id}:postmortem", json.dumps(postmortem_stub)
                )
                self.redis_client.lpush("incidents:all", incident_id)

            report_results = {
                "timestamp": datetime.now().isoformat(),
                "step": "4_report",
                "incident_id": incident_id,
                "postmortem_file": str(postmortem_file),
                "filed_within_sla": True,  # Filed immediately
            }

            logger.info(f"âœ… STEP 4 COMPLETE: Post-mortem stub filed as {incident_id}")
            return report_results

        except Exception as e:
            logger.error(f"Error in report step: {e}")
            return {"step": "4_report", "error": str(e)}

    def step5_prevent(
        self, incident_id: str, incident_data: Dict[str, any]
    ) -> Dict[str, any]:
        """
        Step 5: Add prevention measures.

        Args:
            incident_id: Incident identifier
            incident_data: Combined incident data

        Returns:
            Prevention results
        """
        try:
            logger.info("ðŸ›¡ï¸ STEP 5: PREVENT - Adding prevention measures")

            prevention_results = {
                "timestamp": datetime.now().isoformat(),
                "step": "5_prevent",
                "incident_id": incident_id,
                "actions": {},
            }

            # Create prevention plan based on incident type
            severity = incident_data.get("triage", {}).get("severity", "Unknown")
            description = incident_data.get("incident_description", "").lower()

            prevention_actions = []

            if "recon" in description or "reconciliation" in description:
                prevention_actions.extend(
                    [
                        "Add more frequent reconciliation checks",
                        "Implement position drift alerts",
                        "Create automated position validation",
                    ]
                )

            if "entropy" in description or "rl" in description:
                prevention_actions.extend(
                    [
                        "Add RL entropy monitoring alerts",
                        "Implement policy validation checks",
                        "Create RL health dashboard",
                    ]
                )

            if "market data" in description or "feed" in description:
                prevention_actions.extend(
                    [
                        "Add data feed staleness alerts",
                        "Implement backup data sources",
                        "Create data quality monitoring",
                    ]
                )

            # Generic prevention actions
            prevention_actions.extend(
                [
                    "Review and update monitoring thresholds",
                    "Add incident-specific test cases",
                    "Update runbook procedures",
                ]
            )

            prevention_results["actions"]["prevention_plan"] = prevention_actions

            # Create prevention tracking file
            prevention_file = Path(
                f"artifacts/incidents/incident_{incident_id}_prevention_plan.json"
            )
            prevention_data = {
                "incident_id": incident_id,
                "created": datetime.now().isoformat(),
                "prevention_actions": prevention_actions,
                "status": "planned",
                "assignments": [],
                "completion_target": (datetime.now() + timedelta(days=7)).isoformat(),
            }

            with open(prevention_file, "w") as f:
                json.dump(prevention_data, f, indent=2)

            prevention_results["actions"]["prevention_file"] = str(prevention_file)

            logger.info("âœ… STEP 5 COMPLETE: Prevention measures documented")
            return prevention_results

        except Exception as e:
            logger.error(f"Error in prevention step: {e}")
            return {"step": "5_prevent", "error": str(e)}

    def run_full_sop(self, incident_description: str) -> Dict[str, any]:
        """
        Run complete 5-step incident SOP.

        Args:
            incident_description: Description of the incident

        Returns:
            Complete SOP execution results
        """
        try:
            logger.critical(
                f"ðŸš¨ INCIDENT SOP: Starting full procedure for: {incident_description}"
            )

            sop_results = {
                "timestamp": datetime.now().isoformat(),
                "incident_description": incident_description,
                "steps": {},
            }

            # Step 1: Stabilize
            sop_results["steps"]["stabilization"] = self.step1_stabilize(
                incident_description
            )

            # Step 2: Triage
            sop_results["steps"]["triage"] = self.step2_triage(incident_description)

            # Step 3: Recover
            sop_results["steps"]["recovery"] = self.step3_recover()

            # Step 4: Report
            sop_results["steps"]["report"] = self.step4_report(sop_results["steps"])

            # Step 5: Prevent
            incident_id = sop_results["steps"]["report"].get("incident_id")
            if incident_id:
                sop_results["steps"]["prevent"] = self.step5_prevent(
                    incident_id, sop_results["steps"]
                )

            # Overall success assessment
            sop_results["overall_success"] = self._assess_sop_success(sop_results)

            logger.info("âœ… INCIDENT SOP: Complete procedure executed")
            return sop_results

        except Exception as e:
            logger.error(f"Error running full SOP: {e}")
            return {"error": str(e)}

    def _snapshot_redis(self) -> Optional[str]:
        """Create Redis snapshot."""
        try:
            if not self.redis_client:
                return None

            snapshot_dir = Path("artifacts/incidents/snapshots")
            snapshot_dir.mkdir(parents=True, exist_ok=True)

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            snapshot_file = snapshot_dir / f"redis_snapshot_{timestamp}.json"

            # Get critical Redis keys
            critical_keys = [
                "mode",
                "risk:*",
                "pilot:*",
                "rl:*",
                "metrics:*",
                "features:*",
                "exec:*",
                "incident:*",
            ]

            snapshot_data = {}
            for pattern in critical_keys:
                keys = self.redis_client.keys(pattern)
                for key in keys[:100]:  # Limit to first 100 keys per pattern
                    try:
                        value = self.redis_client.get(key)
                        snapshot_data[key] = value
                    except:
                        continue

            with open(snapshot_file, "w") as f:
                json.dump(snapshot_data, f, indent=2)

            return str(snapshot_file)

        except Exception as e:
            logger.error(f"Error creating Redis snapshot: {e}")
            return None

    def _snapshot_logs(self) -> Optional[str]:
        """Create logs snapshot."""
        try:
            snapshot_dir = Path("artifacts/incidents/snapshots")
            snapshot_dir.mkdir(parents=True, exist_ok=True)

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            logs_file = snapshot_dir / f"logs_snapshot_{timestamp}.txt"

            # Try to capture recent logs (platform-dependent)
            try:
                # Try journalctl for systemd logs
                result = subprocess.run(
                    ["journalctl", "-u", "trading-system", "--since", "1 hour ago"],
                    capture_output=True,
                    text=True,
                    timeout=30,
                )
                if result.returncode == 0:
                    with open(logs_file, "w") as f:
                        f.write(result.stdout)
                    return str(logs_file)
            except:
                pass

            # Fallback: create placeholder
            with open(logs_file, "w") as f:
                f.write(f"Log snapshot created at {datetime.now()}\n")
                f.write("Note: Automatic log collection not available\n")

            return str(logs_file)

        except Exception as e:
            logger.error(f"Error creating logs snapshot: {e}")
            return None

    def _execute_canary_rollback(self) -> Dict[str, any]:
        """Execute canary rollback."""
        try:
            # Mock canary rollback - would typically call actual canary system
            logger.info("Executing canary rollback...")

            if self.redis_client:
                # Disable promoted features
                promoted_features = [
                    "features:rl_exec_live",
                    "features:nautilus_live_exec",
                    "features:bandit_weights_live",
                ]

                for feature in promoted_features:
                    self.redis_client.set(feature, "0")

                return {"success": True, "features_rolled_back": promoted_features}
            else:
                return {"success": False, "reason": "Redis unavailable"}

        except Exception as e:
            return {"success": False, "error": str(e)}

    def _verify_reconciliation(self) -> Dict[str, any]:
        """Verify reconciliation is clean."""
        try:
            if self.redis_client:
                recon_breach = bool(
                    int(self.redis_client.get("pilot:recon_breach_active") or 0)
                )
                return {"clean": not recon_breach, "breach_active": recon_breach}
            else:
                return {"clean": False, "reason": "Redis unavailable"}

        except Exception as e:
            return {"clean": False, "error": str(e)}

    def _run_preflight_supercheck(self) -> Dict[str, any]:
        """Run preflight supercheck."""
        try:
            # Mock preflight - would typically run actual preflight script
            logger.info("Running preflight supercheck...")

            checks = [
                "Redis connectivity",
                "Feature flag consistency",
                "Configuration validation",
                "Service health",
                "Data feeds",
            ]

            return {"all_green": True, "checks_passed": checks, "checks_failed": []}

        except Exception as e:
            return {"all_green": False, "error": str(e)}

    def _generate_incident_id(self) -> str:
        """Generate unique incident ID."""
        timestamp = datetime.now().strftime("%Y%m%d")

        if self.redis_client:
            # Increment counter for the day
            counter_key = f"incidents:counter:{timestamp}"
            counter = self.redis_client.incr(counter_key)
            self.redis_client.expire(counter_key, 86400 * 7)  # Expire after 1 week
        else:
            counter = 1

        return f"INC-{timestamp}-{counter:03d}"

    def _determine_impact(self, incident_data: Dict[str, any]) -> str:
        """Determine incident impact."""
        severity = incident_data.get("triage", {}).get("severity", "Unknown")

        impact_map = {
            "P0": "High - Funds at risk, immediate financial impact",
            "P1": "Medium - Trading degraded, potential revenue loss",
            "P2": "Low - Monitoring/shadow systems affected",
        }

        return impact_map.get(severity, "Unknown impact")

    def _build_incident_timeline(
        self, incident_data: Dict[str, any]
    ) -> List[Dict[str, str]]:
        """Build incident timeline."""
        timeline = []

        for step_name, step_data in incident_data.items():
            if isinstance(step_data, dict) and "timestamp" in step_data:
                timeline.append(
                    {
                        "time": step_data["timestamp"],
                        "event": f"{step_name.title()} completed",
                        "details": step_data.get("step", step_name),
                    }
                )

        return sorted(timeline, key=lambda x: x["time"])

    def _assess_sop_success(self, sop_results: Dict[str, any]) -> bool:
        """Assess overall SOP execution success."""
        try:
            # Check if critical steps succeeded
            stabilization_ok = (
                not sop_results.get("steps", {}).get("stabilization", {}).get("error")
            )
            recovery_ok = (
                sop_results.get("steps", {})
                .get("recovery", {})
                .get("recovery_successful", False)
            )
            report_ok = not sop_results.get("steps", {}).get("report", {}).get("error")

            return stabilization_ok and recovery_ok and report_ok

        except Exception:
            return False


def parse_args():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(description="Incident SOP Manager")

    parser.add_argument(
        "--description", type=str, required=True, help="Incident description"
    )
    parser.add_argument(
        "--step",
        type=str,
        choices=["1", "2", "3", "4", "5", "full"],
        default="full",
        help="Run specific step or full SOP",
    )
    parser.add_argument("--output", type=str, help="Output file for results")

    return parser.parse_args()


def main():
    """Main function."""
    args = parse_args()

    logger.info("ðŸš¨ Starting Incident SOP Manager")

    try:
        manager = IncidentSOPManager()

        if args.step == "full":
            results = manager.run_full_sop(args.description)
        elif args.step == "1":
            results = manager.step1_stabilize(args.description)
        elif args.step == "2":
            results = manager.step2_triage(args.description)
        elif args.step == "3":
            results = manager.step3_recover()
        elif args.step == "4":
            # Need previous step data for step 4
            logger.error(
                "Step 4 requires data from previous steps. Use --step full instead."
            )
            return 1
        elif args.step == "5":
            # Need previous step data for step 5
            logger.error(
                "Step 5 requires data from previous steps. Use --step full instead."
            )
            return 1
        else:
            results = manager.run_full_sop(args.description)

        print(f"\nðŸš¨ INCIDENT SOP RESULTS:")
        print(json.dumps(results, indent=2))

        # Save results if requested
        if args.output:
            with open(args.output, "w") as f:
                json.dump(results, f, indent=2)
            logger.info(f"Results saved to {args.output}")

        return 0

    except Exception as e:
        logger.error(f"Error in incident SOP: {e}")
        return 1


if __name__ == "__main__":
    exit(main())
